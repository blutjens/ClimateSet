# @package _global_
# to execute this experiment run:
# python run.py experiment=example

defaults:
  - override /mode: exp.yaml
  - override /trainer: default.yaml
  - override /model: unet.yaml # put the desired model name here
  - override /callbacks: default.yaml
  - override /logger: wandb.yaml
  - override /datamodule: climate.yaml # standard datamodule configurations

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
# can also be accessed by loggers
name: "NorESM2-LM_unet_tas_run-01"

seed: 22201
#seed: 7
#seed: 972

trainer:
  min_epochs: 0
  max_epochs: 0
#   accelerator: "cpu"

reload_model_from_cfg: True

model:
  loss_function: "climax_lon_lat_rmse"
  monitor: "val/llrmse_climax"
  finetune: True
  pretrained_ckpt_dir: "checkpoints/epoch=49-step=2950.ckpt" # trained on shapes without longitude dim. (..., 96)
  pretrained_run_id: 64y0zy7t
#  pretrained_ckpt_dir: "/d3/lutjens/bc3/data/raw/climateset/pretrained_models/single_emulator/Unet/NorESM2-LM_run2_single_emulator_tas+pr_unet/64y0zy7t/checkpoints/epoch=49-step=2950.ckpt"

datamodule: # overwrite what stuff to train on
    # more selection like climate models and scenarios + splits should go here
    # ...
   in_var_ids: ['BC_sum', 'CO2_sum', 'SO2_sum', 'CH4_sum']
   out_var_ids: ['tas', 'pr']
   train_historical_years: "1850-2010"
   train_models:  ["NorESM2-LM"]
   #   seq_length: 120
   seq_to_seq: True # determine the task setting
   batch_size: 4
   channels_last: False
   eval_batch_size: 4

logger:
  wandb:
          tags: ["single_emulator", "unet", "NorESM2-LM", "tas+pr", "run1"] # set your tags here
          #resume: False
          #reinit: False
